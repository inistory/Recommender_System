
# Chapter 3 Model-Based Collaborative Filtering

# 3.1 Introduction

**요약**
- Collaborative filtering은 NEIGHBORHOOD-BASED COLLABORATIVE FILTERING과 Model-Based Collaborative Filtering로 나뉨
-  3장에서는 Model-Based 을 다룸
- 모델기반 방법은 머신러닝 기반으로 평점을 예측
- **행 : 유저**
- **열: 아이템**

---
**Neighborhood-based Collaborative Filtering**
- 이웃 기반 방법은 기계 학습에서 일반적으로 사용되는 k-최근접 이웃 분류기를 일반화한 것
- 이러한 방법은 인스턴스 기반 방법이므로 효율적인 구현을 위해 필요한 선택적 사전 처리1 단계 외에는 예측을 위해 미리 모델을 특별히 생성하지 않습니다. 
- 이웃 기반 방법은 인스턴스 기반 학습 방법의 일반화 또는 예측 접근 방식이 예측되는 인스턴스에 특정한 지연 학습 방법입니다. 
- 예를 들어, 사용자 기반 이웃 방법에서는 예측을 수행하기 위해 대상 사용자의 피어가 결정됩니다.
- ---
**Model-based Collaborative Filtering**
- 모델 기반 방법에서는 지도 또는 비지도 기계 학습 방법과 마찬가지로 데이터의 요약 모델이 미리 생성됨
-  따라서 훈련(또는 모델 구축 단계)은 예측 단계와 명확하게 분리
- 전통적인 기계 학습에서 이러한 방법의 예로는 의사 결정 트리, 규칙 기반 방법, Bayes 분류기, 회귀 모델, 지원 벡터 기계 및 신경망
- 흥미롭게도, k-최근접 이웃 분류기가 협업 필터링을 위해 이웃 기반 모델로 일반화될 수 있는 것처럼 거의 모든 이러한 모델은 협업 필터링 시나리오로 일반화될 수 O
-  이는 전통적인 분류 및 회귀 문제가 행렬 완성(또는 협업 필터링) 문제의 특수한 경우이기 때문입니다.

 **p72**
-Figure 3.1: Revisiting Figure 1.4 of Chapter 1. Comparing the traditional classification problem with collaborative filtering. Shaded entries are missing and need to be predicted.
- 데이터 분류 문제에서 첫 번째(n − 1) 열이 특성 변수(또는 독립 변수)이고 마지막(즉, n번째) 열이 클래스 변수(또는 종속 변수)인 m × n 행렬이 있습니다. ). 
- 첫 번째(n − 1) 열의 모든 항목은 완전히 지정되지만 n번째 열의 항목 하위 집합만 지정됩니다. 
- 따라서 행렬에 있는 행의 하위 집합이 완전히 지정되고 이러한 행을 훈련 데이터라고 합니다. 
- 나머지 행을 테스트 데이터라고 합니다. 
- 테스트 데이터에 대해 누락된 항목의 값을 학습해야 합니다. 
- 음영 처리된 값은 행렬에서 누락된 항목
- --
-  등급 매트릭스의 항목이 누락될 수 있습니다. 
- 따라서 행렬 완성 문제는 분류(또는 회귀 모델링) 문제의 일반화임을 분명히 알 수 있습니다. 
- 따라서 이 두 문제의 결정적인 차이점은 다음과 같이 요약할 수 있습니다.
--- 
 **Classification과 Collaborative filtering 차이점**
1. **데이터 분류 문제에서 특성(독립) 변수와 클래스(종속) 변수 사이에 명확한 구분**이 있습니다**. 행렬 완성 문제에서는 이러한 명확한 분리가 존재하지 않습니다.** 각 열은 주어진 지점에서 예측 모델링을 위해 고려되는 항목에 따라 종속 및 독립 변수입니다.
2. **데이터 분류 문제에서 훈련 데이터와 테스트 데이터가 명확하게 구분**됩니다. **행렬 완성 문제에서 이 명확한 경계는 행렬의 행 사이에 존재하지 않습니다.** 기껏해야 지정된(관찰된) 항목을 교육 데이터로 간주하고 지정되지 않은(누락된) 항목을 테스트 데이터로 간주할 수 있습니다.
3. **데이터 분류에서 열은 기능을 나타내고 행은 데이터 인스턴스**를 나타냅니다. 그러나 **협업 필터링에서는 누락된 항목이 분산되는 방식 때문에 등급 매트릭스 또는 전치(열과 행 바꿔도됨) 에 동일한 접근 방식을 적용**할 수 있습니다. 예를 들어, 사용자 기반 이웃 모델은 최근접 이웃 분류기의 직접적인 일반화로 볼 수 있습니다. 이러한 방법을 등급 매트릭스의 전치에 적용하면 item-based neighborhood model이라고 합니다. 일반적으로 협업 필터링 알고리즘의 많은 클래스에는 user-wise and item-wise versions 이 있습니다.
---
- 협업 필터링 문제의 더 큰 일반성은 데이터 분류에 비해 협업 필터링에서 더 많은 알고리즘 가능성으로 이어집니다.
- --
**협업 필터링 문제와 데이터 분류 문제 사이의 유사성**  
협업 필터링 문제에 대한 학습 알고리즘을 설계할 때 염두에 두면 유용
- 사실, 대부분의 기계 학습 및 분류 알고리즘은 협업 필터링 문헌에서 직접적인 유사성을 가지고 있습니다.
-  분류 모델과 유사한 방식으로 추천 시스템을 이해하면 분류 문헌에서 가져온 많은 수의 메타 알고리즘을 적용할 수 있습니다. 예를 들어, 배깅, 부스팅 또는 모델 조합과 같은 분류 문헌의 고전적인 메타 알고리즘은 협업 필터링으로 확장될 수 있습니다. 
- 흥미롭게도 분류에서 앙상블 방법을 위해 개발된 이론의 대부분은 계속해서 추천 시스템에 적용됩니다. 사실 앙상블 기반 방법[311, 704]은 Netflix 챌린지에서 가장 성능이 좋은 방법 중 하나였습니다. 
- --
- 그러나 데이터 분류 모델을 행렬 완성 문제로 직접 일반화하는 것이 항상 쉬운 것은 아닙니다. 
- 특히 대부분의 항목이 누락된 경우에는 더욱 그렇습니다. 
- 더욱이 다양한 모델의 상대적 효율성은 상황에 따라 다릅니다. 예를 들어, 잠재 요인 모델과 같은 많은 최근 협업 필터링 모델은 협업 필터링에 특히 적합합니다. 그러나 이러한 모델은 데이터 분류의 맥락에서 경쟁 모델로 간주되지 않습니다.
---
**model based 장점**
		1. **공간 효율성:** 일반적으로 학습된 모델의 크기는 원래 등급 매트릭스보다 훨씬 작습니다. 따라서 공간 요구 사항은 종종 매우 낮습니다. 반면에 사용자 기반 이웃 방법은 O(m2) 공간 복잡도를 가질 수 있습니다. 여기서 m은 사용자 수입니다. item 기반 방법은 O(n2) 공간 복잡도를 갖습니다. 계산할게 줄어든다.
		2. **학습 속도 및 예측 속도:** 이웃 기반 방법의 한 가지 문제는 전처리 단계가 사용자 수 또는 item 수에서 2차적이라는 것입니다. **모델 기반 시스템은 일반적으로 훈련된 모델을 구성하는 전처리 단계에서 훨씬 빠릅니다.** 대부분의 경우 간결하고 요약된 모델을 사용하여 예측을 효율적으로 수행할 수 있습니다.
		3. **과적합 방지:** 과적합은 분류 및 회귀 모델에서도 발생합니다. 모델 기반 방법의 요약 접근 방식은 종종 과적합을 피하는 데 도움이 될 수 있습니다. 또한 정규화 방법을 사용하여 이러한 모델을 견고하게 만들 수 있습니다.

---
**Neighborhood-based Collaborative Filtering 한계**
- 이웃 기반 방법이 가장 초기의 협업 필터링 방법 중 하나였으며 단순성 때문에 가장 인기가 있었지만 오늘날 사용할 수 있는 가장 정확한 모델은 아닙니다. 
- 사실, 가장 정확한 방법 중 일부는 일반적으로 모델 기반 기술, 특히 잠재 요인 모델을 기반으로 합니다.
- --
**3장의 구성**
- 3.2 : 추천 시스템을 위한 의사 결정 및 회귀 트리의 사용
-  3.3 : 규칙 기반 협업 필터링 방법
-  3.4: 추천 시스템에 대한 순진한 Bayes 모델의 사용
- 3.5:  다른 분류 방법이 협력 필터링으로 확장되는 방법에 대한 일반적인 논의
- 3.6 : 잠재 요인 모델
- 3.7 : 잠재 요인 모델과 이웃 모델의 통합
- 3.8 : 요약
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTM3NTI5ODk1LC0xNjk2NDM1MjcwLDczMD
k5ODExNl19
-->