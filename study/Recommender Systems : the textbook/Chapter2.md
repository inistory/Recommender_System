

# Chapter 2

##  2.3.4 Comparing User-Based and Item-Based Methods

### p42
-   사용자 자신의 평가가 추천을 수행하는 데 사용된다는 사실 때문에 더 관련성 높은 추천을 제공하는 경우가 많습니다.
    
-   유사한 Contents를 대상 Content과 식별하고 해당 content에 대한 사용자 자신의 평점을 사용하여 대상의 평점을 추정합니다.
    
-   예를 들어, 대상 역사 영화와 유사한 content은 다른 역사 영화 세트일 수 있습니다. 이러한 경우 smiliar set 대한 사용자 자신의 추천은 대상에 대한 선호도를 크게 나타낼 수 있습니다.
    
-   이는 중복되지만 다른 관심을 가질 수 있는 다른 사용자로부터 등급을 추정하는 사용자 기반 방법의 경우가 아닙니다.
    
-   결과적으로 항목 기반 방법이 더 나은 정확도를 보이는 경우가 많습니다.

---
    
-   Item-based methods이 더 정확할 가능성이 높지만 Item-based methodsr과 User-Based Method 간의 상대적 정확도도 현재 데이터 세트에 따라 다릅니다. 
-  Item-based methods은 추천 시스템의 siling attacks 에도 더 강력합니다.
-  반면에 Item-based methods보다 User-Based Method 에 대한 추천 프로세스의 다양성을 높일 수 있습니다.
- 다양성 : items in the ranked list 이 다소 다른 경향이 있다는 사실을 나타냅니다. 
- 항목이 다양하지 않은 경우 사용자가 첫 번째 항목을 좋아하지 않는다면 목록의 다른 항목도 좋아하지 않을 수 있습니다. 
- Item-based methods 은 때때로 명백한 contents 또는 이전 사용자 경험에서 새롭지 않은 contents을 추천할 수 있습니다. 
- 참신, 다양성, 우연의 개념은 7장에서 자세히 설명합니다. 새로움, 다양성, 우연이 충분하지 않으면 사용자는 이미 본 것과 매우 유사한 추천 항목에 지루해할 수 있습니다.
- -- 

### p43
- Item-based methods은 추천에 대한 구체적인 이유를 제공할 수도 있습니다. 
- 예를 들어 Netflix는 종종 다음과 같은 문구로 권장 사항을 제공합니다.
	-'날개의 비밀'을 시청하셨기 때문에 [추천은] ⟨목록⟩ 입니다.
-이러한 설명은 using the item neighborhoods을 사용하여 item-based methods으로 구체적으로 해결할 수 있습니다. 
- 반면, 피어 그룹은 단순히 익명 사용자의 집합이며 추천 프로세스에서 직접 사용할 수 없기 때문에 이러한 설명은 User-Based으로 다루기가 더 어렵습니다.
- -- 
-  User-Based은 다양한 유형의 설명을 제공합니다. 
-  예를 들어 영화 Terminator, Alien, and Predator 가 Alice에게 추천된다면 이 영화에 대한 이웃의 평가 히스토그램을 그녀에게 표시할 수 있습니다. (Figure 2.2)
- Alice는 이 히스토그램을 사용하여 이 영화를 얼마나 좋아할지 알 수 있습니다. 
- 단점: 이러한 유형의 설명의 힘이 부족
	- Alice에게 이러한 영화가 자신의 취향이나 실제로 알고 신뢰하는 친구의 취향과 어떤 관련이 있는지에 대한 정보제공 못함
	- 그녀의 이웃의 신원은 개인 정보 보호 문제로 인해 Alice에게 제공되지 않습니다.
---
- item-based methods은 등급이 변경됨에 따라 더 안정적
	- 이유1: 사용자 수는 일반적으로 item 수보다 훨씬 많습니다. 이러한 경우 두 사용자가 상호 평가한 항목의 수는 매우 적을 수 있지만 두 item은 공동 평가한 사용자 수가 더 많을 가능성이 더 큽니다.  
	- User-Based의 경우 몇 가지 등급을 추가하면 유사도 값이 크게 변경될 수 있습니다. 하지만 등급 값의 변화에 ​​더 안정적인건 item-based methods 
- 이유2: 새 사용자는 새 item보다 상용 시스템에서 더 자주 추가될 가능성이 높습니다. 이러한 경우 이웃 item의 계산은 새로운 사용자가 추가되더라도 item 이웃이 크게 변경되지 않을 가능성이 높기 때문에 가끔씩만 수행될 수 있습니다. 
- 한편, 사용자 이웃의 계산은 신규 사용자가 추가됨에 따라 더 자주 수행될 필요가 있다. 
- 이러한 맥락에서 추천 모델의 점진적 유지 관리는 User-Based 의 경우 더 어렵습니다.
--- 
### p44

## 2.3.5 Strengths and Weaknesses of Neighborhood-Based Methods
- 이웃 방법은 단순성과 직관적 접근과 관련된 몇 가지 장점 존재
-  구현 및 디버그가 쉽습니다.
-  특정 item이 권장되는 이유를 정당화하기 쉬운 경우가 많으며 item-based의 해석 가능성이 특히 두드러집니다. 
- 이러한 정당화는 종종 이후 장에서 논의되는 많은 model-based 에서 쉽게 사용할 수 없습니다. 
- 또한 새로운 아이템과 사용자가 추가되면서 추천이 상대적으로 안정적입니다. 
- 이러한 방법의 증분 근사치를 생성하는 것도 가능합니다.
---
- 단점1 : 대규모 설정에서 오프라인 단계가 때때로 비실용적일 수 있다는 것 
- User-Based의 오프라인 단계는 최소한 O(m2)의 시간과 공간이 필요, m이 수천만 정도인 경우 데스크탑 하드웨어에서는 너무 느리거나 공간 집약적 일 수 O
- 그럼에도 불구하고  neighborhood methods의 온라인 단계는 항상 효율적
- 단점2 : Sparsity(희소성) 으로 인해 적용 범위가 제한적
- 예시) John의 가장 가까운 이웃이 Terminator를 평가하지 않은 경우 John에 대해 Terminator의 평가 예측을 제공할 수 없음
- 반면에 우리는 대부분의 추천 설정에서 John의 top-k 항목에만 신경을 씀, John의 가장 가까운 이웃 중 누구도 Terminator를 평가하지 않았다면 이 영화가 John에게 좋은 추천이 아니라는 증거일 수 O 
- Sparsity 은 또한 두 사용자 간의 상호 평가 항목 수가 적을 때 강력한 유사성 계산에 대한 문제를 만듦

## 2.3.6 A Unified View of User-Based and Item-Based Methods
- User-based과 Item-based 의 각각의 약점
- User-based 가 등급 매트릭스의 열 간의 유사성을 무시하는 반면 Item-based는 가장 유사한 항목을 결정하면서 행 간의 유사성을 무시한다는 사실에서 발생
- 두 가지 방법을 통합하여 target 과 가장 유사한 항목을 결정할 수 있는지에 대한 자연스러운 질문이 발생합니다. 그렇게 함으로써 행이나 열을 따라 유사성을 무시할 필요가 없습니다. 오히려 행과 열 사이의 유사성 정보를 결합할 수 있습니다.
- --
- 이 목표를 달성하려면 행이 평균 중심이 되면 사용자 기반 방법과 항목 기반 방법이 거의 동일하다
-  각 행의 평균이 예측 후 각 항목에 다시 추가될 수 있기 때문에 일반성을 잃지 않고 평가 행렬의 행이 평균 중심이라고 가정할 수 있습니다. 
- 행이 평균 중심이면 행 간의 Pearson 상관 계수가 코사인 계수와 동일
- 이러한 가정을 바탕으로 User-based 및 Item-based 을 통합적으로 설명할 수 O

### p45
- 평가 행렬 R에서 항목 ruj를 예측합니다.
	1.  targetentry(u,j)에 대해 행/열 사이의 코사인 계수를 사용하여 ratings matrix의 가장 유사한 행/열 결정합니다. User-based의 경우 행이 사용되는 반면 Item-based 의 경우 열이 사용됩니다.
	2. 첫 번째 단계에서 결정된 가장 유사한 행/열에 있는 등급의 가중치 조합을 사용하여 대상 항목(u, j)을 예측합니다.
---
- 앞서 언급한 설명은 각 단계의 행이나 열을 무시합니다.  행과 열에 따른 유사성과 예측 정보가 결합되는 앞서 언급한 단계에 대한 일반화된 설명
	1. target entry(u,j)에 대해 행과 열 간의 유사도 조합 함수를 사용하여 등급 매트릭스의 가장 유사한 항목을 결정합니다. 예를 들어, 행 사이와 열 사이의 코사인 유사성의 합을 사용하여 등급 매트릭스에서 (u,j)에 대한 가장 유사한 항목을 결정할 수 있습니다.
	2. 첫 번째 단계에서 결정된 가장 유사한 항목의 등급의 가중치 조합을 사용하여 대상 항목(u, j)을 예측합니다. 가중치는 첫 번째 단계에서 계산된 유사도를 기반으로 합니다.
---
- 일반화된 방법에서 다른 단계를 강조 
- 조합 함수를 사용하여 행과 열을 따라 유사성을 융합
- 가장 효과적인 결과를 얻기 위해 다양한 조합 함수를 사용하여 실험가능
- user, item 및 기타 컨텍스트 차원의 유사성이 단일 프레임워크로 통합되는 컨텍스트 기반 추천 시스템의 다차원 모델에서도 사용됩니다
## 2.4 Clustering and Neighborhood-Based Methods
- 이웃 기반 방법의 주요 문제는 오프라인 단계의 복잡성
- 사용자 수 또는 항목 수가 매우 많을 때 상당히 중요할 수 있습니다. 
- 예를 들어, 사용자 m이 몇 억 정도인 경우 사용자 기반 방법의 O(m2·n') 실행 시간은 가끔 오프라인 계산에도 비실용적이 됩니다. 
- m = 108이고 n′ = 100인 경우, O(m2 · n′) = O(1018) 연산이 필요
-  각 작업에 기본 기계 주기가 필요하다고 보수적으로 가정하면 10GHz 컴퓨터에는 108초가 소요되며 이는 약 115.74일입니다. 
- 확장성 관점에서 그다지 실용적이지 않음.
- --
- 클러스터링 기반 방법은 오프라인에서 가장 가까운 이웃 계산 단계를 오프라인 클러스터링 단계로 대체하는 것
-  오프라인에서 가장 가까운 이웃 단계가 가능한 각 대상에 중심을 둔 많은 수의 피어 그룹을 생성하는 것처럼 클러스터링 프로세스는 각 가능한 대상에 반드시 중심에 있지는 않은 더 적은 수의 피어 그룹을 만듭니다. 
- 클러스터링 프로세스는 가능한 모든 대상의 피어 그룹을 구성하는 데 필요한 O(m2·n') 시간보다 훨씬 효율적
- 클러스터가 구성되면 등급 예측 프로세스는 식 2.4에서 사용된 접근 방식과 유사합니다. 주요 차이점은 동일한 클러스터 내에서 가장 가까운 상위 k개 피어가 예측을 수행하는 데 사용된다는 것
- pairwise similarity computation (쌍별 유사도 계산) 은 동일한 클러스터 내에서만 수행되어야 하므로 접근 방식이 훨씬 더 효율적일 수 O
- 클러스터 내의 각 대상에 가장 가까운 이웃 집합이 전체 데이터보다 품질이 낮기 때문에 정확도가 약간 손실
- 클러스터링 세분성은 정확도와 효율성 간의 균형을 조절
-  클러스터가 세분화되면 효율성은 향상되지만 정확도는 떨어집니다. 
- 정확도가 약간 감소하더라도 효율성이 매우 크게 향상될 수 있습니다. 
- 등급 매트릭스가 매우 큰 경우 이 접근 방식은 적은 비용으로 매우 실용적인 대안을 제공

### p46
- 이 접근 방식을 사용할 때의 한 가지 문제는 등급 매트릭스가 완전하지 않다는 사실
-  따라서 클러스터링 방법은 엄청나게 불완전한 데이터 세트와 함께 작동하도록 조정되어야 합니다. 
- 이러한 맥락에서 k-평균 방법은 불완전한 데이터에 쉽게 적용할 수 있습니다. 
- k-평균 접근 방식의 기본 아이디어는 k개의 서로 다른 클러스터의 대표자 역할을 하는 k개의 중심점(또는 "평균")으로 작업하는 것
- k-means 방법에서 클러스터링에 대한 솔루션은 이러한 k 대표의 specification(사양)으로 완전히 나타낼 수 있습니다. 
- k개의 대표자 집합이 주어졌을 때 Y1 . . . Yk , 각 데이터 포인트는 유사성 또는 거리 함수를 사용하여 가장 가까운 대표에 할당
- 따라서 데이터 분할은 대표 집합에 의해 고유하게 정의될 수 O
- m × n 데이터 세트의 경우 각 대표 Yi는 i번째 클러스터의 중심점인 n차원 데이터 포인트입니다. 
- 이상적으로는 중심 대표가 클러스터의 평균이 되기를 바랍니다.
---
- 따라서 클러스터는 representatives(대표자)에 종속되며 그 반대의 경우도 마찬가지입니다. 
- 이러한 상호 의존성은 반복적인 접근 방식으로 달성됩니다. 
- representative(대표자 집합) Y1 .. Yk : 데이터 공간의 범위에서 생성된 무작위로 선택된 포인트
- representative(대표자)를 사용하여 클러스터 파티션을 반복적으로 계산한 다음 결과 클러스터의 중심으로 representative(대표자)를 다시 계산
- 중심을 계산하는 동안 각 차원에서 관찰된 값만 사용하도록 주의해야 합니다. 
- 이 2단계 반복 접근 방식은 수렴을 위해 실행됩니다. 2단계 접근 방식은 다음과 같이 요약됩니다.
	1. m×n 행렬의 각 행을 Y1...Yk에서 가장 가까운 대표에 할당하여 군집 C1 ... Ck 을 결정합니다.  일반적으로 유사도 계산에는 유클리드 거리 또는 맨해튼 거리가 사용됩니다.
	2. 각 i ∈ {1...k}에 대해 Yi를 Ci의 현재 점 집합의 중심으로 재설정합니다.
---
- 이 접근 방식을 사용할 때의 주요 문제는 m × n 등급 매트릭스가 완전하지 않다는 것
- 따라서 평균 및 거리 값의 계산은 정의되지 않음
- 그러나 클러스터 내에서 관찰된 값만 사용하여 평균을 계산하는 것은 비교적 쉬움
-  경우에 따라 클러스터에 있는 하나 이상의 항목에 대해 등급이 지정되지 않은 경우 중심 자체가 완전히 지정되지 않을 수 O
- 거리 값은 데이터 포인트와 클러스터 대표 모두에 대해 지정된 차원의 하위 집합만을 사용하여 계산
- 거리는 또한 계산에 사용된 차원 수로 나뉨
- 이것은 모든 중심이 완전히 지정되지 않은 경우 다양한 중심에 대한 데이터 포인트의 거리를 계산하기 위해 다른 차원 수를 사용한다는 사실을 조정하기 위해 수행
-  이러한 맥락에서 맨해튼 거리는 유클리드 거리보다 조정이 더 잘 이루어지며 정규화된 값은 각 관측값에 따른 평균 거리로 더 쉽게 해석될 수 있습니다.
---
- 앞서 언급한 접근 방식은 사용자 기반 협업 필터링을 위해 행을 클러스터링합니다. 
- 항목 기반 방법에서는 열을 클러스터링해야 합니다.
- 접근 방식은 행이 아닌 열에 적용된다는 점을 제외하고는 완전히 유사합니다. 
- efficient collaborative filtering 방법 중 일부는 사용자 기반 방법이고 다른 방법은 항목 기반 방법입니다. 여러 공동 클러스터링 방법[643]을 사용하여 행과 열을 동시에 클러스터링할 수 있습니다.

### p47
## 2.5 Dimensionality Reduction and Neighborhood Methods
- Dimensionality reduction methods(차원 축소 방법)은 품질 및 효율성 면에서 이웃 기반 방법을 개선하는 데 사용
- 특히, pairwise similarities(쌍별 유사도)는 희소 등급 매트릭스에서 강력하게 계산하기 어렵지만 차원 축소는 la- tent factors (잠재 요인) 측면에서 조밀한 저차원 표현을 제공
-  따라서 이러한 모델을 잠재 요인 모델이라고도 함
-  두 명의 사용자가 공통으로 평가하는 항목이 거의 없는 경우에도 저차원 잠재 벡터 사이의 거리를 계산할 수 있음
- 저차원 잠재 벡터로 피어 그룹을 결정하는 것이 더 효율적
-  차원 축소 방법에 대한 세부 사항을 논의하기 전에 추천 시스템에서 잠재 요인 모델을 사용하는 두 가지 방법에 대해 몇 가지 설명합니다.
	1. 데이터의 축소된 표현은 행 단위 잠재 요인 또는 열 단위 latent factors(잠재 요인) 관점에서 생성될 수 있습니다. 즉, 축소된 표현은 item 차원 또는 user 차원을 잠재 요소로 압축합니다. 이 축소된 표현은 the sparsity problem for neighborhood-based models(이웃 기반 모델의 희소성 문제) 를 완화하는 데 사용할 수 있습니다. 어떤 차원이 잠재 요인으로 압축되었는지에 따라 축소된 표현은 사용자 기반 이웃 알고리즘 또는 item-based neighborhood algorithms 에 사용될 수 O
	2. 행 공간과 열 공간 모두의 잠재 표현이 동시에 결정됩니다. 이러한 잠재 표현은 이웃 기반 방법을 사용하지 않고 전체 등급 매트릭스를 한 번에 재구성하는 데 사용됩니다.
---
- the second class of methods 은 인접 기반 방법과 직접적인 관련이 없기 때문에 이 장에서는 다루지 않습니다. 메서드의 두 번째 클래스에 대한 자세한 설명은 3장에서 제공될 것입니다. 이 장에서는 the first class of methods에만 초점을 맞출 것입니다.
- --
- user-based collaborative filtering 기본 아이디어는 주성분 분석을 사용하여 m × n 등급 행렬 R을 저차원 공간으로 변환하는 것입니다. 
- 결과 행렬 R'의 크기는 m × d이며, 여기서 d ≪ n입니다.
-  따라서, 사용자에 대응하는 등급의 (희소한) n차원 벡터 각각은 축소된 d차원 공간으로 변환됨
- 또한 원래 등급 벡터와 달리 각 d 차원이 완전히 지정됩니다. 
- 각 사용자의 이 d-차원 표현이 결정된 후, 축소 표현을 사용하여 대상 사용자에서 각 사용자에 대한 유사도가 계산됩니다.
-  축소된 표현의 유사성 계산은 새로운 저차원 벡터가 완전히 지정되기 때문에 더 강력
-  또한, 유사성 계산은 잠재 표현의 차원이 낮기 때문에 더 효율적
- 축소된 벡터에 대한 간단한 코사인 또는 내적은 이 축소된 공간에서 유사성을 계산하기에 충분
- --
- 각 데이터 포인트의 저차원 표현이 어떻게 계산되는지 설명해야 함
- 저차원 표현은 SVD와 같은 방법이나 PCA와 같은 방법을 사용하여 계산할 수 O
-  다음에서는 SVD와 유사한 방법을 설명합니다.

### p48
- Table 2.3: Example of bias in estimating covariances(공분산 추정의 편향)
- 첫 번째 단계는 누락된 항목을 채우기 위해 m × n개의 불완전 등급 행렬 R을 증가시키는 것입니다.
-  누락된 항목은 행렬의 해당 행의 평균(즉, 해당 사용자의 평균 등급)과 동일한 것으로 추정됩니다. 
- 다른 접근 방식은 누락된 항목을 행렬의 해당 열의 평균(즉, 해당 항목의 평균 등급)으로 추정하는 것입니다. 
- 결과 행렬을 Rf로 표시합니다. 그런 다음 S = RfT Rf로 주어진 항목 쌍 간의 n × n 유사성 행렬을 계산
- 이 행렬은 양의 semi-definite(준정부호)입니다. SVD에 대한 Rf의 지배적 기저 벡터를 결정하기 위해 다음과 같이 유사성 행렬 S의 대각화를 수행합니다.

S = PΔPT (2.16)
- P는 n × n 행렬로, 열에 S의 직교 고유 벡터가 포함
-  Δ는 S의 음이 아닌 고유값이 대각선을 따라 포함된 대각 행렬입니다.
- Pd를 가장 큰 고유벡터에 해당하는 P의 열만 포함하는 n × d 행렬
-  그런 다음 Rf의 저차원 표현은 행렬 곱 Rf Pd에 의해 제공
- Rf는 m×n 행렬이고 Pd는 n×d 행렬이기 때문에 축소 표현 Rf Pd의 차원은 m × d
- 따라서 m명의 사용자 각각은 이제 d차원 공간에 표시됨
-  그런 다음 이 표현을 사용하여 각 사용자의 피어 그룹을 결정
-  피어가 결정되면 식 2.4를 사용하여 등급 예측을 쉽게 수행할 수 있습니다. 이러한 접근 방식은 전체 차원 축소 방법을 Rf 대신 Rf의 전치에 적용하여 항목 기반 협업 필터링에도 사용할 수 있습니다.
- --
- 앞서 언급한 방법론은 평가 행렬 Rf의 특이값 분해(SVD)로 볼 수 있습니다.
-  다른 많은 방법[24, 472]은 SVD 대신 주성분 분석(PCA)을 사용하지만 전체 결과는 매우 유사합니다.
-  PCA 방법에서는 유사도 행렬 RfT Rf 대신 Rf 의 공분산 행렬이 사용됩니다. 
- 열을 따라 평균 중심에 있는 데이터의 경우 두 가지 방법이 동일합니다. 
- 따라서 항목에서 각 열의 평균을 뺀 다음 앞서 언급한 접근 방식을 적용하여 변환된 데이터 표현을 얻을 수 있습니다. 
- 이 변환된 표현은 각 사용자의 피어를 결정하는 데 사용됩니다. 평균 중심화는 편향을 줄이는 측면에서 이점이 있습니다(다음 섹션 참조). 
- 다른 방법은 먼저 각 행을 따라 중심을 평균한 다음 각 열을 따라 중심을 평균하는 것입니다. 
- 변환된 표현에 SVD를 적용할 수 있습니다. 이러한 유형의 접근 방식은 일반적으로 가장 강력한 결과를 제공합니다.

## 2.5.1 Handling Problems with Bias
- 행렬 Rf는 행이나 열을 따라 평균값으로 지정되지 않은 항목을 채워 불완전 행렬 R에서 파생됩니다. 
- 이러한 접근 방식은 상당한 편향을 유발할 수 있습니다. 
- 이러한 편향의 특성을 이해하기 위해 12명의 사용자가 Godfather, Gladiator 및 Nero의 세 가지 영화에 대해 부여한 등급에 대한 표 2.3의 예를 고려하십시오. 
- PCA가 차원 축소에 사용되므로 공분산 행렬을 추정해야 한다고 가정합니다. 
- 결측값이 열을 따라 평균으로 대체된다고 가정해 보겠습니다.
- --
- 이 경우 3편의 영화에 대해 4명의 사용자가 1에서 7까지 등급을 매깁니다. 
- 영화 'Gladiator'와 'Nero'의 시청률 사이의 상관관계가 극도로 높다는 것을 시각적으로 알 수 있다. 
- 지정된 4가지 경우에 등급이 매우 유사하기 때문이다.
-  Godfather와 Gladiator의 상관관계는 덜 중요한 것 같습니다. 
- 그러나 많은 사용자가 Nero에 대한 등급을 지정하지 않았습니다.
-  Nero의 평균 등급은 (1 + 7 + 1 + 7)/4 = 4이므로 이러한 지정되지 않은 등급은 평균 값 4로 대체됩니다.
-  이러한 새 항목을 추가하면 Gladiator와 Nero 간의 추정 공분산이 크게 줄어듭니다. 
- 그러나 새 항목을 추가해도 Godfather와 Gladiator 간의 공분산에는 영향을 미치지 않습니다. 
- 누락된 등급을 채운 후 세 영화 간의 쌍별 공분산은 다음과 같이 추정할 수 있습니다.
|  |  |
|--|--|
|  |  |
--- 
- 앞서 말한 추정에 따르면 Godfather와 Gladiator의 공분산은 Gladiator와 Nero의 공분산보다 더 큽니다.
-  Gladiator와 Nero에 대한 표 2.3의 등급이 둘 다 지정된 경우에 동일하기 때문에 이는 정확하지 않은 것으로 보입니다. 
- 따라서 Gladiator와 Nero의 상관관계는 더 높아야 한다. 
- 이 오류는 지정되지 않은 항목을 해당 열의 평균으로 채워서 발생하는 편향의 결과입니다. 
- 이러한 종류의 편향은 대부분의 항목이 지정되지 않기 때문에 희소 행렬에서 매우 중요할 수 있습니다. 
- 따라서 지정되지 않은 항목 대신 평균 등급을 사용하여 발생하는 편향을 줄이기 위한 방법을 설계해야 합니다. 
- 다음에서는 이 문제에 대한 두 가지 가능한 솔루션을 탐색합니다.

### 2.5.1.1 Maximum Likelihood Estimation
- 개념적 재구성 방법[24, 472]은 공분산 행렬을 추정하기 위해 EM-알고리즘과 같은 확률적 기법의 사용을 제안한다. 
- 데이터에 대해 생성 모델이 가정되고 지정된 item이 생성 모델의 결과로 간주됩니다. 
- 공분산 행렬은 이 생성 모델의 매개변수를 추정하는 과정의 일부로 추정할 수 있습니다. 
- 다음에서 우리는 이 접근 방식의 단순화를 제공합니다. 
- 이 단순화된 접근 방식에서는 공분산 행렬의 최대 가능도 추정치가 계산됩니다. 
- 각 item쌍 간의 공분산의 Maximum Likelihood Estimation(최대 가능도 추정치) 는 지정된 item 간의 공분산으로만 추정됩니다.
-  즉, 특정 항목 쌍에 대해 지정된 등급을 가진 사용자만 공분산을 추정하는 데 사용됩니다. 
- 한 쌍의 항목 간에 공통 사용자가 없는 경우 공분산은 0으로 추정됩니다. 
- 이 접근 방식을 사용하여 표 2.3의 데이터에 대해 다음 공분산 행렬을 추정합니다.
|  |  |
|--|--|
|  |  |
---
- 이 경우 Gladiator와 Nero 간의 공분산이 Godfather와 Gladiator 간의 공분산의 거의 3배
- 게다가 영화 네로는 원래 추정치보다 3배 이상의 편차가 있고 모든 영화 중 평점 편차가 가장 큽니다. 
-  Godfather와 Gladiator 간의 pairwise covariance은 평균 채우기 기술을 사용하는 다른 모든 pairwise covariance과 비교하여 가장 컸지만, 이제 이 동일한 쌍이 모든 pairwise covariance 중 가장 작은 값을 보여줍니다. 
- 이 예는 편향 보정이 일부 상황에서 매우 중요할 수 있음을 시사합니다.
-  행렬에서 지정되지 않은 item의 비율이 클수록 평균 채우기 기법의 편향이 커집니다. 
- 따라서 지정된 item만 활용하는 수정된 기술이 공분산 행렬을 계산하는 데 사용됩니다. 
- 이러한 기술이 항상 효과적인 것은 아니지만 평균 채우기 기술보다 우수합니다. 
- 감소된 n × d 기저 행렬 Pd는 결과 공분산 행렬의 상위 d개의 고유 벡터를 선택하여 계산됩니다.
--- 
- 표현의 편향을 더 줄이기 위해 불완전 행렬 R은 채워진 행렬 Rf를 Pd에 투영하는 대신 축소된 행렬 Pd에 직접 투영할 수 있습니다.
-  아이디어는 Pd의 각 잠재 벡터에 대한 투영에 대해 관찰된 각 등급의 기여도를 계산한 다음 이러한 등급 수에 대한 기여도를 평균화하는 것입니다. 
- 이 평균 기여도는 다음과 같이 계산됩니다. ei를 pd의 i번째 열(고유벡터)이라고 하고, j번째 항목이 eji라고 합니다.
-  ruj를 행렬 R의 항목 j에 대한 사용자 u의 관찰된 등급이라고 합니다. 
- 그러면 잠재 벡터 ei에 대한 투영에 대한 사용자 u의 기여도는 rujeji로 표시됩니다. 
- 그런 다음 집합 Iu가 사용자 u의 지정된 항목 등급의 인덱스를 나타내는 경우 i번째 잠재 벡터에 대한 사용자 u의 평균 기여도 aui는 다음과 같습니다.
- ---
- (2.17)
- 이러한 유형의 평균 정규화는 다른 사용자가 다른 수의 등급을 지정한 경우에 특히 유용합니다. 
- 결과 m × d 행렬 A = [aui]m×d는 기본 등급 행렬의 축소 표현으로 사용됩니다. 
- 이 축소 행렬은 사용자 기반 협업 필터링을 위해 대상 사용자의 이웃을 효율적으로 계산하는 데 사용됩니다.
-  행렬 R의 전치에 접근 방식을 적용하고 항목 차원이 아닌 사용자 차원을 따라 차원을 줄이는 것도 가능합니다. 
- 이러한 접근 방식은 항목 기반 협업 필터링에서 대상 항목의 이웃을 계산하는 데 유용합니다. 
- 결측값 대치에 대해 축소 표현을 사용하는 이러한 접근 방식은 [24, 472]에서 논의됩니다.

### 2.5.1.2 Direct Matrix Factorization of Incomplete Data
- 앞서 언급한 방법론은 공분산 추정의 편향을 어느 정도 수정할 수 있지만 등급의 희소성 수준이 높을 때 완전히 효과적이지 않습니다. 
- 이는 공분산 행렬 추정이 강력한 추정을 위해 각 항목 쌍에 대해 충분한 수의 관측 등급이 필요하기 때문입니다. 
- 행렬이 희소인 경우 공분산 추정치는 통계적으로 신뢰할 수 없습니다.
- ---
- 보다 직접적인 접근 방식은 행렬 분해 방법을 사용하는 것입니다. 특이값 분해와 같은 방법은 본질적으로 행렬 분해 방법입니다. 
- m×n 등급 행렬 R이 완전히 지정되었다고 가정합니다. 
- (완전히 지정된) 행렬 R은 다음과 같이 인수분해될 수 있습니다.
- (2.18)
- --
- 여기서 Q는 RRT의 m개의 직교 고유 벡터를 포함하는 열이 있는 m×m 행렬입니다.
-  행렬 P는 RT R의 n개의 직교 고유 벡터를 포함하는 열이 있는 n × n 행렬입니다. 
- Σ는 m × n 대각 행렬로, 대각 항목4만 0이 아니고 RT R의 0이 아닌 고유값의 제곱근을 포함합니다. (또는 동등하게 RRT ). 
- RT R과 RRT의 고유 벡터는 동일하지 않고 m ̸= n일 때 차원이 다릅니다. 
- 그러나 값이 동일한 동일한 수(0이 아닌) 고유값을 항상 갖습니다. 
- Σ의 대각선에 있는 값을 특이값이라고도 합니다.
- --
- 또한 d ≤ min{m, n} 가장 큰 특이값에 해당하는 고유 벡터만 사용되는 절단된 SVD를 사용하여 행렬을 대략적으로 인수분해할 수 있습니다. 
- 잘린 SVD는 다음과 같이 계산됩니다.
- (2.19)
- ---
- 여기서 Qd, Σd, Pd는 각각 m×d, d×d, n×d 행렬이다. 
- 행렬 Qd 및 Pd는 각각 RRT 및 RTR의 큰 고유 벡터를 포함하는 반면, 행렬 Σd는 대각선을 따라 각 행렬의 가장 큰 고유값 d개의 제곱근을 포함합니다.
-  행렬 Pd는 차원 축소에 필요한 축소 기저 표현인 RT R의 상위 고유 벡터를 포함한다
- 더욱이, 행렬 QdΣd는 Pd에 대응하는 기초에서 원래 등급 행렬의 변환 및 축소된 m × d 표현을 포함합니다.
-  이러한 근사 분해는 다른 순위 d 분해와 비교하여 근사 항목의 최소 제곱 오차를 갖는다는 것을 보여줄 수 있습니다. 
- 따라서 식 2.19에 해당하는 형식으로 등급 행렬 R을 대략적으로 인수분해할 수 있다면 축소 기반과 축소 기반 등급의 표현을 제공합니다. 
- 이러한 접근 방식을 사용할 때의 주요 문제는 등급 매트릭스가 완전히 지정되지 않는다는 것입니다. 
- 결과적으로 이 인수분해는 정의되지 않습니다. 그럼에도 불구하고 공식을 최적화 문제로 재구성하는 것이 가능합니다. 
- 여기서 인수분해의 제곱 오차는 등급 매트릭스의 관찰된 항목에 대해서만 최적화됩니다. 
- 비선형 최적화 기술을 사용하여 이 수정된 공식을 명시적으로 푸는 것도 가능합니다. 
- 이는 견고하고 편향되지 않은 저차원 표현을 생성합니다. 또한, 이러한 접근 방식은 일단  reduced factor matrices가 결정되면 식 2.19를 사용하여 등급 매트릭스를 직접 추정하는 데 사용할 수 있습니다.
-  즉, 이러한 방법은 neighborhood-based methods. 을 넘어 직접적인 효용을 갖는다. 
- 이러한 잠재 요인 모델과 비선형 최적화 기술에 대한 자세한 내용은 3장의 섹션 3.6에서 논의될 것입니다. 
- 독자는 이 섹션을 참조하여 수정된 최적화 공식을 사용하여 축소 표현을 계산하는 방법을 배워야 합니다.

## 2.6 A Regression Modeling View of Neighborhood Methods
- User-based 과 item-based 모두에 대한 중요한 관찰은 이웃 사용자가 동일한 항목에 대해 평가하거나 이웃 item 에 대해 동일한 사용자가 평가하는 선형 함수로 평가를 예측한다는 것입니다. 
- 이 점을 이해하기 위해 사용자 기반 이웃 방법의 예측 기능을 복제합니다(참조, 식 2.4).
- ( 2 . 2 0 )
- --
- 예상 등급은 동일한 항목의 다른 등급의 가중 선형 조합입니다. 
- 선형 조합은 타겟 사용자 u와 충분히 유사한 취향을 가진 사용자에 속하는 항목 j의 등급으로 제한되었습니다. 
- 이 제한은 피어 평가 세트 Pu(j)를 사용하여 활성화됩니다. 이 장의 앞부분에 있는 논의에서 Pu(j)는 항목 j도 평가한 대상 사용자 u에 가장 가까운 k 사용자의 집합이라는 것을 상기하십시오.
- 집합 Pu(j)가 항목 j의 모든 등급(특정 피어 사용자뿐만 아니라)을 포함하도록 허용하면 예측 함수가 선형 회귀의 것과 유사하게 됩니다[22]. 
- 선형 회귀에서 등급은 다른 등급의 가중 조합으로도 예측되며 가중치(계수)는 최적화 모델을 사용하여 결정됩니다. 이웃 기반 접근 방식에서 선형 함수의 계수는 최적화 모델을 사용하는 대신 사용자-사용자 유사성을 통해 발견적 방법으로 선택됩니다.
- --
- 예측 함수(방정식 2.15 참조)가 다음과 같은 항목 기반 이웃 방법의 경우에도 유사한 관찰이 적용됩니다.
- (2.21)
- --
- 집합 Qt(u)는 사용자 u가 평가한 대상 항목 t에 가장 가까운 k 항목 집합을 나타냅니다.
-  이 경우 대상 항목 t에 대한 사용자 u의 등급은 자신의 등급의 선형 조합으로 표현됩니다. 
- 사용자 기반 방법의 경우와 마찬가지로 선형 조합의 계수는 유사성 값으로 휴리스틱하게 정의됩니다.
-  따라서 사용자 기반 모델은 동일한 열에 있는 평가의 선형 조합으로 예측된 평점을 표현하는 반면, item 기반 모델은 동일한 행에 있는 평점의 선형 조합으로 예측된 평점을 표현합니다.
-  이러한 관점에서, 이웃 기반 모델은 선형 회귀 모델의 발견적 변형이며, 회귀 계수는 관련(인접) item/user에 대한 유사성 값으로 발견적으로 설정되고 관련되지 않은 item/user에 대해 0으로 설정됩니다.
- --
- 유사도 값을 조합 가중치로 사용하는 것이 오히려 발견적이며 임의적이라는 점은 주목할 만합니다. 
- 또한 계수는 항목 간의 상호 의존성을 설명하지 않습니다. 
- 예를 들어, 사용자가 매우 유사한 방식으로 특정 상관 항목 집합을 평가한 경우 이러한 항목과 관련된 계수도 상호 의존적입니다.
-  휴리스틱 가중치로 유사성을 사용하는 것은 그러한 상호 의존성을 설명하지 않습니다.
- --
- 최적화 공식을 사용하여 가중치를 학습하여 더 잘할 수 있는지에 대한 질문이 발생합니다. 
- 사용자 기반 및 항목 기반 모델과 유사한 회귀 기반 모델을 도출할 수 있음이 밝혀졌습니다. 
- 사용자 기반 모델, 항목 기반 모델 또는 이 둘의 조합을 활용할 수 있는 여러 가지 최적화 공식이 문헌에서 제안되었습니다. 
- 이러한 모델은 발견적 최근접 이웃 모델의 이론적 일반화로 볼 수 있습니다. 
- 이러한 모델의 장점은 명확한 최적화 공식의 맥락에서 수학적으로 더 잘 기반을 두고 있으며 모델링 관점에서 최적으로 인해 등급을 결합하기 위한 가중치가 더 잘 정당화될 수 있다는 것입니다. 
- 다음에서는 [309]의 작업을 단순화한 최적화 기반 이웃 모델에 대해 논의합니다. 이것은 또한 3장의 섹션 3.7에서 이 모델의 능력을 행렬 인수분해와 같은 다른 최적화 모델과 결합하기 위한 단계를 설정합니다.

## 2.6.1 User-Based Nearest Neighbor Regression
- 식 2.20의 사용자 기반 예측을 고려하십시오. 
- 예측 등급 rˆ을 모델링하기 위해 (정규화된) 유사성 계수를 알려지지 않은 매개변수 wuser로 바꿀 수 있습니다.
다음과 같이 항목 j에 대한 대상 사용자 u의:
- (2.22)
- -- 
- 이웃 모델의 경우와 같이 Pearson 상관 계수를 사용하여 Pu(j)를 정의할 수 있습니다. 
- 그러나 이 경우 Pu(j)가 정의되는 방식에는 미묘하지만 중요한 차이가 있습니다. 
- 이웃 기반 모델에서 Pu(j)는 항목 j에 대한 등급을 지정한 대상 사용자 u에 가장 가까운 k 사용자의 집합입니다.
-  따라서 최소 k명의 사용자가 항목 j를 평가할 때 Pu(j)의 크기는 종종 정확히 k입니다. 
- 회귀 방법의 경우 집합 Pu(j)는 먼저 각 사용자에 대해 k개의 가장 가까운 피어를 결정한 다음 등급이 관찰된 것만 유지하여 정의됩니다.
-  따라서 집합 Pu(j)의 크기는 종종 k보다 훨씬 작습니다. 매개변수 k는 해석이 다르기 때문에 이웃 모델과 비교하여 회귀 프레임워크에서 훨씬 더 큰 값으로 설정해야 합니다.
- --
- 직관적으로 알 수 없는 계수 wuser는 등급 vu의 예측 부분을 제어합니다.
- 이 부분이 wuser · (r − μ )에 의해 제공되기 때문에 사용자 u에 의해 제공되며, 이는 사용자 v와 그녀의 유사성에서 비롯됩니다.
-  wuser 가 wuser 와 다를 수 있습니다. 또한 주목할 만하다.
- wuser는 vu에 가장 가까운 v(사용자 인덱스)의 k개의 다른 값에 대해서만 정의됩니다.
사용자 u는 피어슨 계수를 기반으로 합니다. 
wuser의 다른 값은 vu에 필요하지 않습니다.
식 2.22의 예측 함수이므로 학습할 필요가 없습니다.
- 이는 회귀 계수의 수를 줄이는 유익한 효과가 있습니다.
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTYyNDU2MzEzMywzNDE4NDQwMjQsLTMxMT
Q5NzYzOSwxMjQ2MTMyMDU4LC0xNjA3MzU5NjY0LDE0ODU5OTA4
NzYsNzMwOTk4MTE2XX0=
-->
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTQwNDI3OTEyNywtMTQ2ODA2Mzg2NSwtMz
cxMzgyMjA1LDczMDk5ODExNl19
-->